{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n",
      "Changed working dir to /home/spandan/Projects/hubbard-transformer\n"
     ]
    }
   ],
   "source": [
    "from boilerplate import setup_nb\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "device = setup_nb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops as ein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PARAMS = 2\n",
    "TOKEN_DIMS = 32\n",
    "PARAM_DIMS = 16\n",
    "MAX_LEN = 100\n",
    "POSSIBLE_OCCS = 5\n",
    "POSSIBLE_SPINS = 2\n",
    "BATCH_SIZE = 32\n",
    "DIM_FF = 64\n",
    "N_HEADS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from real_hubbard import RealHubbardModel\n",
    "\n",
    "model = RealHubbardModel(\n",
    "    token_dims=TOKEN_DIMS,\n",
    "    param_dims=PARAM_DIMS,\n",
    "    n_params=N_PARAMS,\n",
    "    dim_feedforward=DIM_FF,\n",
    "    n_heads=N_HEADS,\n",
    "    possible_occupations=POSSIBLE_OCCS,\n",
    "    possible_spin_states=POSSIBLE_SPINS,\n",
    "    max_len=MAX_LEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2693,  1.7680,  0.0407, -0.2895, -0.3189, -1.4457, -0.7183,  0.6513,\n",
       "         -2.6162,  0.3217, -0.4829,  0.9051, -0.6850,  0.9658,  0.4653,  0.0197,\n",
       "         -0.2150, -0.8779, -0.7323, -1.3476,  0.1181, -0.7828, -0.1732, -0.8612,\n",
       "          0.1227, -1.2930, -0.3915, -1.0149, -0.6239,  0.6849, -1.6701,  1.5768],\n",
       "        [-0.0368,  1.1987, -0.1401, -0.3019, -0.6885,  0.7202,  1.3430, -1.1189,\n",
       "          0.6786,  0.0631, -0.8008, -0.8255,  0.2116,  1.7506,  0.0718, -0.8219,\n",
       "         -1.5608,  0.1322,  0.2785, -0.2284,  2.1324, -0.2075,  1.0202, -0.7024,\n",
       "          0.3903, -0.3738,  0.3747,  1.4419,  0.4551, -1.0820,  0.8178,  0.8229]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_params = torch.randn(N_PARAMS, BATCH_SIZE)\n",
    "test_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (5) must match the existing size (32) at non-singleton dimension 1.  Target sizes: [32, 5, 2].  Tensor sizes: [32, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39msample_states(params\u001b[38;5;241m=\u001b[39mtest_params, occupations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, target_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/hubbard-transformer/real_hubbard.py:170\u001b[0m, in \u001b[0;36mRealHubbardModel.sample_states\u001b[0;34m(self, params, occupations, target_len)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Autoregressiely populate the empty space in the buffer\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m current_len \u001b[38;5;241m<\u001b[39m target_len:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# TODO: avoid re-embedding params each time\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# TODO: can we do any elimination here?\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_next(\n\u001b[1;32m    171\u001b[0m         params,\n\u001b[1;32m    172\u001b[0m         occupations\u001b[38;5;241m=\u001b[39mbuffer[:current_len, :, :, :],\n\u001b[1;32m    173\u001b[0m         out\u001b[38;5;241m=\u001b[39mbuffer[current_len : current_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, :, :, :],\n\u001b[1;32m    174\u001b[0m     )\n\u001b[1;32m    175\u001b[0m     current_len \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m params, buffer\n",
      "File \u001b[0;32m~/Projects/hubbard-transformer/real_hubbard.py:97\u001b[0m, in \u001b[0;36mRealHubbardModel.sample_next\u001b[0;34m(self, params, occupations, out)\u001b[0m\n\u001b[1;32m     94\u001b[0m probs \u001b[38;5;241m=\u001b[39m ein\u001b[38;5;241m.\u001b[39mrearrange(prob, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb o sp -> b sp o\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     95\u001b[0m next_token \u001b[38;5;241m=\u001b[39m Categorical(probs)\u001b[38;5;241m.\u001b[39msample()  \u001b[38;5;66;03m# (batch, spins)\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m out[\u001b[38;5;241m0\u001b[39m, :, :, :] \u001b[38;5;241m=\u001b[39m next_token\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# TODO: We should only have one occupation number per site\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(next_token\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (5) must match the existing size (32) at non-singleton dimension 1.  Target sizes: [32, 5, 2].  Tensor sizes: [32, 2]"
     ]
    }
   ],
   "source": [
    "model.sample_states(params=test_params, occupations=None, target_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1364e+00,  6.2708e-01,  8.0199e-01, -3.7813e-01,  2.0832e+00],\n",
       "         [-1.3912e-01, -1.8972e+00,  2.2890e-01, -2.4975e-01,  7.3279e-01]],\n",
       "\n",
       "        [[ 1.7789e+00,  5.3803e-01, -5.3401e-01, -1.1629e+00,  3.0956e-01],\n",
       "         [ 1.3836e+00, -2.3823e-01, -6.1807e-01,  3.9193e-01, -8.1285e-01]],\n",
       "\n",
       "        [[ 9.8771e-01, -1.1152e+00, -1.1199e+00,  5.7620e-01,  5.1309e-01],\n",
       "         [ 2.5526e-01, -3.7195e-02, -3.5027e-01,  1.4633e+00, -4.2341e-01]],\n",
       "\n",
       "        [[-3.8063e-01,  1.1556e-02, -1.5331e+00,  1.7920e+00,  1.2367e+00],\n",
       "         [-1.2447e+00,  8.1868e-01,  1.0883e+00, -2.2686e-02,  6.1754e-02]],\n",
       "\n",
       "        [[-1.3097e+00, -1.9059e-01,  1.4433e+00,  5.3135e-01, -8.9197e-01],\n",
       "         [-1.1648e+00,  5.2712e-01,  5.3764e-01, -4.2571e-01, -7.7426e-02]],\n",
       "\n",
       "        [[-1.3033e+00, -3.1892e-02, -1.1511e+00,  9.6663e-01,  1.0295e+00],\n",
       "         [-1.5729e+00,  6.3164e-02,  6.3287e-02, -3.3892e-01, -8.3731e-01]],\n",
       "\n",
       "        [[-2.7246e-01, -2.0187e-01, -9.3419e-01, -1.3689e+00,  7.8526e-01],\n",
       "         [-4.6269e-01, -3.5394e-02,  9.7403e-01,  1.1692e-01, -1.5294e-01]],\n",
       "\n",
       "        [[ 1.6105e-01, -5.8137e-01, -4.2564e-02, -1.4780e+00, -8.2572e-01],\n",
       "         [-1.1009e+00,  1.1431e-01, -1.0555e+00,  1.4649e+00,  2.9660e-01]],\n",
       "\n",
       "        [[ 1.8293e+00, -1.3056e+00,  1.8828e+00, -7.7002e-01, -2.5832e-03],\n",
       "         [-6.9621e-01, -1.3781e+00,  2.5105e-01,  8.7518e-01,  7.9737e-01]],\n",
       "\n",
       "        [[ 1.2352e+00, -1.6053e+00, -9.5729e-01, -3.7497e-01,  4.9457e-01],\n",
       "         [ 3.0117e-01, -1.6778e-01, -5.1892e-01, -3.1428e-01, -9.2791e-02]],\n",
       "\n",
       "        [[-4.6271e-01, -3.1759e-01,  1.6234e+00, -2.0158e+00,  2.1258e-01],\n",
       "         [-3.2582e-01,  9.5648e-01, -8.2234e-01,  1.5882e+00, -2.6478e-01]],\n",
       "\n",
       "        [[ 4.0340e-01, -2.8954e-01,  9.7086e-01,  9.8079e-02,  2.3554e-01],\n",
       "         [-8.6777e-01, -6.0052e-01, -2.0583e-01, -5.1604e-01,  1.4013e-01]],\n",
       "\n",
       "        [[ 5.9292e-01, -1.0679e+00, -9.2457e-01,  5.1813e-01, -6.4757e-01],\n",
       "         [-1.5295e+00, -9.8729e-01,  2.9851e-01, -5.7922e-01,  1.2321e+00]],\n",
       "\n",
       "        [[ 1.9605e-01, -1.4260e+00, -1.3187e+00,  3.7790e-01,  3.6652e-01],\n",
       "         [-6.3381e-01,  8.5832e-01,  4.8480e-01, -1.2043e+00,  5.3108e-01]],\n",
       "\n",
       "        [[-6.5499e-01, -1.2428e+00,  1.0366e+00, -6.4473e-02,  1.1050e+00],\n",
       "         [ 1.6457e+00, -8.2789e-02, -5.2813e-01, -4.3068e-01,  2.5607e-01]],\n",
       "\n",
       "        [[-4.3706e-01, -1.7717e-01,  7.4482e-01, -8.0900e-01, -1.6927e-01],\n",
       "         [ 6.4770e-01,  4.5596e-02,  1.6169e+00,  3.3427e-01, -3.5541e-01]],\n",
       "\n",
       "        [[-8.9100e-03, -1.2578e-01, -8.5604e-02, -1.0216e+00,  1.5632e+00],\n",
       "         [-6.9331e-01, -7.5665e-01,  5.7721e-01, -1.1734e-01, -3.7934e-01]],\n",
       "\n",
       "        [[ 1.1822e+00, -1.2664e-03, -8.6947e-01, -3.2845e-01, -6.2701e-01],\n",
       "         [ 1.2332e+00,  1.4567e+00,  5.2964e-01, -1.5004e+00,  1.2269e+00]],\n",
       "\n",
       "        [[ 5.0805e-01, -5.3437e-02,  1.6166e+00,  1.0255e+00,  6.1315e-01],\n",
       "         [ 1.0391e+00,  5.1304e-01,  5.7721e-02,  1.1127e-01, -5.3441e-01]],\n",
       "\n",
       "        [[ 2.9632e-01,  1.6608e+00, -1.6291e+00,  2.1992e+00,  3.9779e-01],\n",
       "         [-1.1258e+00, -1.3528e+00, -4.3391e-01, -4.1597e-01,  1.6382e+00]],\n",
       "\n",
       "        [[ 1.2687e-02,  6.9463e-01,  8.4337e-01,  1.5705e+00,  1.0592e-01],\n",
       "         [ 4.8535e-01,  2.2173e+00,  1.0150e+00, -1.1599e+00, -1.0917e+00]],\n",
       "\n",
       "        [[-1.4805e+00, -2.6473e-01, -2.7482e-01,  7.5000e-01, -2.5879e+00],\n",
       "         [-4.3682e-01, -8.7249e-01, -6.4883e-01, -1.7298e+00,  6.8693e-01]],\n",
       "\n",
       "        [[ 1.8156e+00,  1.6451e+00, -1.0458e+00, -5.7666e-01, -2.5797e-01],\n",
       "         [-1.4281e+00,  5.1533e-01, -8.4632e-01,  1.3278e+00, -7.3787e-01]],\n",
       "\n",
       "        [[ 1.8200e+00,  9.3950e-01,  2.6003e+00,  7.4836e-01,  2.4910e-01],\n",
       "         [ 7.6762e-01,  6.2655e-01,  5.8450e-01, -5.2591e-01,  1.4707e-01]],\n",
       "\n",
       "        [[ 1.0709e+00, -1.0885e+00,  6.7057e-01, -1.1780e+00, -3.1026e-01],\n",
       "         [ 2.1954e+00, -2.7418e-01, -7.2026e-01,  7.7985e-01,  4.7167e-01]],\n",
       "\n",
       "        [[-5.3685e-01,  7.2329e-02,  5.6675e-01, -7.1786e-01, -2.5740e-01],\n",
       "         [-6.0818e-01, -1.1266e+00,  1.4611e+00, -4.6083e-01, -2.5964e-01]],\n",
       "\n",
       "        [[ 1.1408e+00,  9.1809e-01, -2.3681e-01,  9.8010e-01,  1.5999e-01],\n",
       "         [ 5.7650e-01, -1.0334e+00,  7.7123e-01,  1.8252e+00, -2.1650e-01]],\n",
       "\n",
       "        [[ 1.0293e+00, -1.7949e+00,  8.8354e-01,  6.2552e-01, -1.9230e+00],\n",
       "         [ 1.3717e-01,  4.5049e-03,  4.0031e-02,  8.8682e-01, -1.2023e+00]],\n",
       "\n",
       "        [[ 3.1483e-01,  2.1110e-01,  2.1643e+00,  1.6026e-01, -4.5193e-01],\n",
       "         [-1.8745e+00, -8.4262e-01,  6.8436e-01,  1.4966e+00,  1.8946e-01]],\n",
       "\n",
       "        [[-8.7994e-01,  9.2248e-02, -1.3057e+00, -8.6266e-01,  2.0211e+00],\n",
       "         [ 1.7227e+00, -8.8783e-01,  1.0511e+00, -8.7465e-01, -1.4348e+00]],\n",
       "\n",
       "        [[-7.9861e-01,  1.2084e+00, -1.5035e-01, -1.2407e+00, -1.9762e+00],\n",
       "         [ 1.0876e+00,  1.0890e+00, -9.8469e-01, -6.4800e-01,  1.3257e+00]],\n",
       "\n",
       "        [[-1.2505e+00, -3.9129e-01,  1.1011e+00, -9.2898e-01,  1.3471e+00],\n",
       "         [ 2.4025e-01, -1.7660e+00,  1.0231e-01, -7.3013e-01, -1.2123e-02]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs = torch.randn(BATCH_SIZE, POSSIBLE_SPINS, POSSIBLE_OCCS)\n",
    "test_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_idx = Categorical(logits=test_probs).sample()\n",
    "sample_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = torch.zeros(1, BATCH_SIZE, POSSIBLE_OCCS, POSSIBLE_SPINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Index tensor must have the same number of dimensions as self tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# use scatter to populate along\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m samples\u001b[38;5;241m.\u001b[39mscatter(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, index\u001b[38;5;241m=\u001b[39msample\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m), src\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1.0\u001b[39m))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Index tensor must have the same number of dimensions as self tensor"
     ]
    }
   ],
   "source": [
    "# use scatter to populate along\n",
    "samples.scatter(dim=2, index=sample.unsqueeze(2), src=torch.tensor(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqs2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
